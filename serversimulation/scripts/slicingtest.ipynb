{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/laurapaulsen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import codecs\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis.sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from functions import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/Caskroom/miniconda/base/envs/methods3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "stops_path = '../../stop_words.txt'\n",
    "#file_path = '../json/contribute_FB_01122112.json'\n",
    "file_path = '../json/contribute_FB_10101011.json'\n",
    "# file_path = '../json/FB_10101111010.json'\n",
    "ID = file_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "file = open(stops_path,\"r+\")\n",
    "stops = file.read().split()\n",
    "\n",
    "data = load_json(file_path)\n",
    "\n",
    "extracted_posts = extract_posts(data)\n",
    "\n",
    "save_txt(extracted_posts, '../extracted_fb_posts', ID + '.txt')\n",
    "\n",
    "decoded_data = decode('../extracted_fb_posts/' + ID +'.txt')\n",
    "\n",
    "no_mentions = remove_mentions(decoded_data)\n",
    "\n",
    "no_empty_str = [string for string in  no_mentions if string != \"\"]\n",
    "\n",
    "no_empty_str = change_letter(no_empty_str)\n",
    "\n",
    "cleaned_data = clean_text(no_empty_str)\n",
    "\n",
    "cleaned_data = [string for string in cleaned_data if string != \"\"]\n",
    "\n",
    "tokenized_data = tokenize(cleaned_data)\n",
    "\n",
    "lemmatized_data = lemmatize(tokenized_data, nlp = nlp)\n",
    "\n",
    "# After lemmatization we again have words with special letters \n",
    "lemmatized_data = change_char(lemmatized_data)\n",
    "\n",
    "no_stops = remove_stops(lemmatized_data, stops)\n",
    "\n",
    "no_stops = [l for l in no_stops if len(l) != 0]\n",
    "\n",
    "no_stops = rem_single_char(no_stops)\n",
    "\n",
    "bigram = gensim.models.Phrases(no_stops)\n",
    "\n",
    "dictionary = Dictionary(no_stops)\n",
    "corpus = [dictionary.doc2bow(text) for text in no_stops]\n",
    "\n",
    "max_topics = set_max_topics(no_stops)\n",
    "min_topics = 2\n",
    "step = 2\n",
    "x = range(min_topics, max_topics, step)\n",
    "\n",
    "coherence_values = compute_c_v(dictionary = dictionary, \n",
    "                               corpus = corpus, \n",
    "                               texts = no_stops, \n",
    "                               min_topics = min_topics, \n",
    "                               max_topics = max_topics, \n",
    "                               step = step)\n",
    "\n",
    "\n",
    "best_result_index = coherence_values.index(max(coherence_values))\n",
    "\n",
    "\n",
    "ldamodel = LdaModel(corpus = corpus, \n",
    "                    num_topics = x[best_result_index], \n",
    "                    id2word = dictionary,\n",
    "                    update_every = 1,\n",
    "                    passes = 10,\n",
    "                    per_word_topics = True)\n",
    "\n",
    "\n",
    "model = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
    "\n",
    "save_model(model, '../html', ID + '.html')\n",
    "\n",
    "# saving preprocessed data to .txt for generic model\n",
    "if 'contribute' in file_path:\n",
    "    n = 20\n",
    "    if len(no_stops) > n:\n",
    "        data_generic = no_stops[0:n]\n",
    "    else:\n",
    "        data_generic = no_stops\n",
    "\n",
    "    if not os.path.isdir('../generic_model'):\n",
    "        os.mkdir('../generic_model')\n",
    "    \n",
    "    if not os.path.isfile('../generic_model/facebook_generic.txt'):\n",
    "        with open('../generic_model/facebook_generic.txt', 'w') as fp:\n",
    "            pass\n",
    "\n",
    "    # Open a file with access mode 'a'\n",
    "    file_object = open('../generic_model/facebook_generic.txt', 'a')\n",
    "    # Append no_stops at the end of file\n",
    "    file_object.write(str(data_generic)[1:-1])\n",
    "    # Close the file\n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing files\n",
    "if os.path.exists(file_path):\n",
    "  os.remove(file_path)\n",
    "\n",
    "if os.path.exists( '../extracted_fb_posts' + ID + '.txt'):\n",
    "  os.remove( '../extracted_fb_posts' + ID + '.txt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbfd61b9771b25adb48756b02878e03699aa9c48f369525daaaa61fe69c4b1b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('methods3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
